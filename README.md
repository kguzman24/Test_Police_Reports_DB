# Test_Police_Reports_DB

## Overview
Our group is researching **SB524** and exploring how AI may introduce or amplify bias in police reporting. Specifically, we’re analyzing whether certain words or phrases in an officer’s short “narrative” can trigger biased patterns when AI systems expand that text into a full report.

## Goal
To examine how linguistic framing affects AI-generated police reports and to develop a **three-tier bias scale** that categorizes officer language by subjectivity or bias level: neutral/objective, subjective, and language undermining direct legal elements of mpc.

## Progress
- Reviewed psychology and linguistics research on language bias in sexual assault cases.  
- Identified linguistic markers that could signal bias.  
- Currently designing the bias scale.  
- Next: apply the scale to narratives and test AI report generation.  

## Next Steps
1. Finalize the bias scale (Tier 1–3).  
2. Choose an AI text-generation tool (e.g., GPT models).  
3. Feed officer narratives by tier into the model and compare outputs.  
4. Analyze tone, framing, and bias differences.  
 

## Impact
This project contributes to understanding **how human language choices can shape algorithmic outcomes** in policing and supports responsible AI policy development under SB524.
